{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN in Tensorflow\n",
    "\n",
    "Reference : https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch?hl=ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = \"your path!\"\n",
    "\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 128\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 224\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "latent_dim = 1024\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "## Load CelebA\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  dataroot,\n",
    "  seed=123,\n",
    "  image_size=(image_size, image_size),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing\n",
    "augmentation_layer = keras.Sequential([\n",
    "    layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    layers.experimental.preprocessing.CenterCrop(image_size,image_size),\n",
    "    layers.experimental.preprocessing.Normalization()    \n",
    "])\n",
    "image_ds = train_ds.map(lambda x,y: (augmentation_layer(x),y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 112, 112, 64)      4864      \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 56, 56, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 56, 56, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 256)       819456    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 28, 28, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 14, 14, 256)       1638656   \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 14, 14, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 7, 7, 512)         3277312   \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 7, 7, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 25088)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,949,824\n",
      "Trainable params: 5,947,520\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        # Input: (h,w,c) = (224,224,3)\n",
    "        keras.Input(shape=(224, 224, 3)),\n",
    "        layers.Conv2D(64, (5, 5), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        # Input : (112, 112, 64)     \n",
    "        layers.Conv2D(128, (5, 5), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        # Input : (56, 56, 128)     \n",
    "        layers.Conv2D(256, (5, 5), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),     \n",
    "        # Input : (28, 28, 256)     \n",
    "        layers.Conv2D(256, (5, 5), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),     \n",
    "        # Input : (14, 14, 256)             \n",
    "        layers.Conv2D(512, (5, 5), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        # Input : (7, 7, 512)\n",
    "        layers.Flatten(),\n",
    "        # Input : (7*7*512)\n",
    "        layers.Softmax()\n",
    "\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12544)             12845056  \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 12544)            50176     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 12544)             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 256)      1048832   \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 14, 14, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 256)      590080    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 14, 14, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 256)      1048832   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 28, 28, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 28, 28, 256)      590080    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 28, 28, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_4 (ReLU)              (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 56, 56, 128)      524416    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 56, 56, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_5 (ReLU)              (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 112, 112, 64)     131136    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 112, 112, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_6 (ReLU)              (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2DT  (None, 224, 224, 3)      3075      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,836,547\n",
      "Trainable params: 16,809,027\n",
      "Non-trainable params: 27,520\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = keras.Sequential(\n",
    "    [     \n",
    "        # Input: (1024)\n",
    "        layers.Dense(7*7*256, use_bias=False, input_shape=(1024,)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),     \n",
    "        layers.Reshape((7,7,256)),\n",
    "        # Input: (7, 7, 256)\n",
    "        layers.Conv2DTranspose(256, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),     \n",
    "        layers.ReLU(),\n",
    "        # Input: (14, 14, 256)\n",
    "        layers.Conv2DTranspose(256, (3, 3), strides=(1, 1), padding=\"same\"),\n",
    "        layers.BatchNormalization(),     \n",
    "        layers.ReLU(),\n",
    "        # Input: (14, 14, 256)\n",
    "        layers.Conv2DTranspose(256, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),     \n",
    "        layers.ReLU(),\n",
    "        # Input: (28, 28, 256)\n",
    "        layers.Conv2DTranspose(256, (3, 3), strides=(1, 1), padding=\"same\"),\n",
    "        layers.BatchNormalization(),     \n",
    "        layers.ReLU(),\n",
    "        # Input: (28, 28, 256)\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),     \n",
    "        layers.ReLU(),\n",
    "        # Forth layer, Input: (56, 56, 128)\n",
    "        layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.BatchNormalization(),     \n",
    "        layers.ReLU(),\n",
    "     \n",
    "        # Final layer, Input: (112, 112, 64)\n",
    "        layers.Conv2DTranspose(3, (4, 4), strides=(2, 2), padding=\"same\", activation = \"tanh\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate one optimizer for the discriminator and another for the generator.\n",
    "d_optimizer = keras.optimizers.Adam(learning_rate=0.0002)\n",
    "g_optimizer = keras.optimizers.Adam(learning_rate=0.0002)\n",
    "\n",
    "# Instantiate a loss function.\n",
    "loss_fn = keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_images):\n",
    "    # Sample random points in the latent space\n",
    "    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "    # Decode them to fake images\n",
    "    generated_images = generator(random_latent_vectors)\n",
    "    # Combine them with real images\n",
    "    combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "    # Assemble labels discriminating real from fake images\n",
    "    labels = tf.concat(\n",
    "        [tf.ones((batch_size, 1)), tf.zeros((real_images.shape[0], 1))], axis=0\n",
    "    )\n",
    "    # Add random noise to the labels - important trick!\n",
    "    labels += 0.05 * tf.random.uniform(labels.shape)\n",
    "\n",
    "    # Train the discriminator\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = discriminator(combined_images)\n",
    "        d_loss = loss_fn(labels, predictions)\n",
    "    grads = tape.gradient(d_loss, discriminator.trainable_weights)\n",
    "    d_optimizer.apply_gradients(zip(grads, discriminator.trainable_weights))\n",
    "\n",
    "    # Sample random points in the latent space\n",
    "    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "    # Assemble labels that say \"all real images\"\n",
    "    misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "    # Train the generator (note that we should *not* update the weights\n",
    "    # of the discriminator)!\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = discriminator(generator(random_latent_vectors))\n",
    "        g_loss = loss_fn(misleading_labels, predictions)\n",
    "    grads = tape.gradient(g_loss, generator.trainable_weights)\n",
    "    g_optimizer.apply_gradients(zip(grads, generator.trainable_weights))\n",
    "    return d_loss, g_loss, generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1583/1583 [01:50<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at epochs 0: 0.73\n",
      "adversarial loss at epochs 0: 1.31\n",
      "\n",
      "Start epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1583/1583 [01:46<00:00, 14.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at epochs 1: 0.73\n",
      "adversarial loss at epochs 1: 1.31\n",
      "\n",
      "Start epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1583/1583 [01:46<00:00, 14.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at epochs 2: 0.73\n",
      "adversarial loss at epochs 2: 1.31\n",
      "\n",
      "Start epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1583/1583 [01:46<00:00, 14.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at epochs 3: 0.74\n",
      "adversarial loss at epochs 3: 1.31\n",
      "\n",
      "Start epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1583/1583 [01:46<00:00, 14.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at epochs 4: 0.73\n",
      "adversarial loss at epochs 4: 1.31\n",
      "\n",
      "Start epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1583/1583 [01:46<00:00, 14.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at epochs 5: 0.73\n",
      "adversarial loss at epochs 5: 1.31\n",
      "\n",
      "Start epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1583/1583 [01:46<00:00, 14.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at epochs 6: 0.73\n",
      "adversarial loss at epochs 6: 1.31\n",
      "\n",
      "Start epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1583/1583 [01:46<00:00, 14.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at epochs 7: 0.73\n",
      "adversarial loss at epochs 7: 1.31\n",
      "\n",
      "Start epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1583/1583 [01:46<00:00, 14.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at epochs 8: 0.73\n",
      "adversarial loss at epochs 8: 1.31\n",
      "\n",
      "Start epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1583/1583 [01:47<00:00, 14.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss at epochs 9: 0.73\n",
      "adversarial loss at epochs 9: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "tf.keras.backend.clear_session()\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"\\nStart epoch\", epoch + 1)\n",
    "\n",
    "    for _, (real_images,_) in enumerate(tqdm(image_ds)):\n",
    "        # Train the discriminator & generator on one batch of real images.\n",
    "        d_loss, g_loss, generated_images = train_step(real_images)\n",
    "\n",
    "    # Logging.\n",
    "    # Print metrics\n",
    "    print(\"discriminator loss at epochs %d: %.2f\" % (epoch + 1, d_loss))\n",
    "    print(\"adversarial loss at epochs %d: %.2f\" % (epoch + 1, g_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0dd05da7729844209ebe7ae432159a766a502dd01e52b265c7791d26d8fe0247"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
