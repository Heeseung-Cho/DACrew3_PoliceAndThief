{"cells":[{"cell_type":"markdown","metadata":{"id":"Zdg9oEyIZTAh"},"source":["### Convolutional Neural Network(CNN)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vWzjQmJY6qgT"},"source":["### Convolution Layer\n","\n","- Convolution이 어떻게 동작하는지\n","\n","- Maxpooling\n","\n","- Convolution 계산\n","\n","- 최종 처리(flatten and mlp)"]},{"cell_type":"markdown","metadata":{"id":"CK6m40Rq8bYP"},"source":["### Convolution Layer\n","\n","Convolution layer는 합성곱 연산을 이용하는 인공신경망입니다. MLP에서는 각각의 pixel에 대해서 weight를 지정해주지만, CNN에서는 하나의 공유하는 filter를 이용하여 대응하는 pixel들을 곱하는 방식으로 연산이 진행됩니다.\n","\n","이미지를 MLP를 이용하여 연산을 하면, 이미지가 커질수록 그에 따른 weight수가 증가하기 때문에 연산량이 급격하게 늘어나지만, Convolution layer의 경우 공유되는 필터를 통해 더 효율적으로 처리를 할 수 있다는 장점이 있어 Computer vision 분야에서는 대부분의 모델을 Convolution layer를 이용합니다.\n","\n","![image](https://cdn-images-1.medium.com/max/1600/1*EuSjHyyDRPAQUdKCKLTgIQ.png)"]},{"cell_type":"markdown","metadata":{"id":"wUUNmGFg_qWL"},"source":["### Pooling Layer\n","\n","Convolution layer를 통해 얻어진 값들은 pooling layer를 거쳐 downsampling이 됩니다. 평균값을 이용하는 Meanpooling 등 다양한 종류가 있지만 주로 최대값을 이용하는 Maxpooling을 이용하는데, 이를 통해 이미지의 중요한 feature들만 유지하여 연산량을 줄일 수 있게 됩니다.\n","Convolution을 거쳐 나온 activation maps이 있을때, 이를 이루는 convolution layer를 resizing해 새로운 layer를 얻는 것 ( 김성훈 교수님 강의 에서의 Pooling 정의)\n","\n","![image](https://oopy.lazyrockets.com/api/v2/notion/image?src=https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F9b5327fe-d3a8-4f6c-8f43-0ea66973a27f%2FUntitled.png&blockId=b86a2d9d-d6f2-4ae6-920d-47d5438bf9fd)\n"]},{"cell_type":"markdown","metadata":{"id":"HQjYEEfSCBNI"},"source":["### Padding\n","\n","Padding이란 이미지의 각 모서리 부분에 특정 값을 채워 넣어주는 역할을 합니다.\n","Padding을 활용하는 이유는 아래와 같습니다.\n","- 이미지 축소를 막기 위해\n","- Edge pixel data를 충분히 활용하기 위해\n","\n","일반적으로 Convolution layer를 진행하게 된다면 연산 결과가 기존의 이미지보다 작게 나오는 것을 확인하실 수 있습니다."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":404,"status":"ok","timestamp":1658126630727,"user":{"displayName":"‍조희승[ 대학원석·박사통합과정재학 / 인공지능학과 ]","userId":"05467509791062225760"},"user_tz":-540},"id":"CPtnxED0RWU8"},"outputs":[],"source":["def cnn_param(W,F,P, S=1):\n","    \"\"\"\n","    W = width or height\n","    F = Filters (Convolution filter의 크기)\n","    P = Padding \n","    S = stride (몇칸씩 이동할 것인가)\n","    \"\"\"\n","    return (((W - F + 2*P) / S) + 1 )"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1658126647196,"user":{"displayName":"‍조희승[ 대학원석·박사통합과정재학 / 인공지능학과 ]","userId":"05467509791062225760"},"user_tz":-540},"id":"xPA7PEX4DIEf","outputId":"a197da13-7b9e-4334-b28a-ee535daacc36"},"outputs":[{"data":{"text/plain":["26.0"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["cnn_param(28, 3, 0, 1)"]},{"cell_type":"markdown","metadata":{"id":"oXkYxRK3DM6g"},"source":["앞서 설명한것 처럼 Padding을 사용한다면 convolution을 통과한 결과값의 사이즈를 보존할 수 있을 뿐만 아니라, 모서리 부분의 feature까지 살릴 수 있다는 장점이 있습니다.\n","\n","![image](https://miro.medium.com/max/325/1*b77nZmPH15dE8g49BLW20A.png)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1658127007904,"user":{"displayName":"‍조희승[ 대학원석·박사통합과정재학 / 인공지능학과 ]","userId":"05467509791062225760"},"user_tz":-540},"id":"RLbN0YraEjEX","outputId":"1c15529b-15ca-4f87-e34b-74a7de56f152"},"outputs":[{"data":{"text/plain":["28.0"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["cnn_param(28, 3, 1, 1)"]},{"cell_type":"markdown","metadata":{"id":"nORuNTWDEpTP"},"source":["### Fully Connected Layer\n","\n","Convolution layer, pooling layer를 거치다 보면 중간 값들이 작아져 더이상 Convolution layer로의 분석이 의미가 없어지게 됩니다. 최종 의사결정을 마무리하기 위해 마지막 단의 결과를 벡터 형태로 펼쳐서 MLP를 보내게 됩니다. 이 과정이 일어나는 layer를 Fully connected layer라고 합니다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"M5J2u6JrGfZl"},"source":["이 모든 과정을 한번에 그리면 다음과 같이 됩니다.\n","\n","![image](https://miro.medium.com/max/1400/1*u2FJVJpUtXN0IHSelbI94A.png)"]},{"cell_type":"markdown","metadata":{"id":"CkVqFk9TJWwZ"},"source":["### CNN on Tensorflow"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3835,"status":"ok","timestamp":1658128281584,"user":{"displayName":"‍조희승[ 대학원석·박사통합과정재학 / 인공지능학과 ]","userId":"05467509791062225760"},"user_tz":-540},"id":"8bHGtdI1JYyY"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"HO3xulUJLIIg"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-07-28 17:14:09.254348: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["## 약식\n","cnn = tf.keras.models.Sequential()\n","cnn.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n","cnn.add(tf.keras.layers.MaxPooling2D((2, 2)))\n","cnn.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n","cnn.add(tf.keras.layers.MaxPooling2D((2, 2)))\n","cnn.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 26, 26, 32)        320       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n","                                                                 \n","=================================================================\n","Total params: 55,744\n","Trainable params: 55,744\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["cnn.summary() # CNN summary를 통한 층 현황"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6LqD3iXjJZ1S"},"outputs":[],"source":["class CNN(tf.keras.Model):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.layer1 = tf.keras.layers.Conv2d(filter = 32, kernel_size = 3, activation = 'relu', padding = \"same\", input_shape = (28,28,1))\n","        self.pool1 = tf.keras.layers.MaxPooling2D((2,2))\n","        self.layer2 = tf.keras.layers.Conv2d(filter = 64, kernel_size = 3, activation = 'relu', padding = \"same\")\n","        self.pool2 = tf.keras.layers.MaxPooling2D((2,2))\n","        self.flat = tf.keras.layers.Flatten()\n","        self.fc = tf.keras.Dense(10, activation = \"None\")\n","\n","    def call(self, x):\n","        out = self.layer1(x)\n","        out = self.pool1(out)\n","        out = self.layer2(out)\n","        out = self.pool2(out)\n","        out = self.flat(out)\n","        return self.fc(out)"]},{"cell_type":"markdown","metadata":{"id":"ydRLUrX16qeE"},"source":["### CNN on Pytorch"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3064,"status":"ok","timestamp":1658127021682,"user":{"displayName":"‍조희승[ 대학원석·박사통합과정재학 / 인공지능학과 ]","userId":"05467509791062225760"},"user_tz":-540},"id":"0Ar6G7M64dXL"},"outputs":[],"source":["import torch\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":339,"status":"ok","timestamp":1658114019568,"user":{"displayName":"‍조희승[ 대학원석·박사통합과정재학 / 인공지능학과 ]","userId":"05467509791062225760"},"user_tz":-540},"id":"y8QoO7Dt4g2V"},"outputs":[],"source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.layer1 = torch.nn.Sequential(\n","            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n","            torch.nn.ReLU(),\n","            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","        self.layer2 = torch.nn.Sequential(\n","            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","            torch.nn.ReLU(),\n","            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","        self.layer3 = torch.nn.Sequential(\n","            torch.nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n","            torch.nn.ReLU(),\n","            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","        self.fc = torch.nn.Linear(3 * 3 * 64, 10, bias=True)\n","\n","\n","    def forward(self, x):\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = out.view(out.size(0), -1)   # Flatten them for FC\n","        out = self.fc(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNyKmCsAhK3Llqr8RaAtdL7","collapsed_sections":[],"name":"CNN.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.12 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"783d77da72e2987a17ca9f0d62fde790e2fff2dc52e843a963dfb29cfffcbe9d"}}},"nbformat":4,"nbformat_minor":0}
