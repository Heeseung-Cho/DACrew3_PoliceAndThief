{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p_-xHxgCmv2"
      },
      "source": [
        "## GAN in Tensorflow\n",
        "\n",
        "Reference : https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch?hl=ko"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번 시간에는 GAN에서 convolutional layer를 추가해 보자는 아이디어로 발전한 DCGAN에 대해 학습해 보겠습니다!\n",
        "\n",
        "DCGAN에서는 퍼셉트론을 이용해 층을 쌓는 GAN과 달리 모든 layer를 convolutional layer로 쌓습니다.\n",
        "\n",
        "DCGAN에서는 pooling layer를 쓰지 않아서 이미지의 크기를 줄일 수가 없기 때문에 stride와 kernal size를 조절해 이미지의 크기를 조절할 수 있습니다.\n",
        "\n",
        "추가로 batch normalization 과정을 추가해서 학습에 안정성을 부여해 줍니다.\n",
        "\n",
        "CNN과는 달리 fully connected 과정이 없고 오로지 convolutional layer만을 이용해서 학습을 진행하는 것이 큰 특징입니다."
      ],
      "metadata": {
        "id": "RUM3QuMwari1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6r3CvluHCmv8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_V3grqq7BmM",
        "outputId": "8669642d-5627-42b0-87db-7533f057a001"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eRMW6Wm8CmwA"
      },
      "outputs": [],
      "source": [
        "# Root directory for dataset\n",
        "dataroot = \"/content/drive/MyDrive/new/\"\n",
        "\n",
        "# Number of workers for dataloader\n",
        "workers = 2\n",
        "\n",
        "# Batch size during training\n",
        "batch_size = 128\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this\n",
        "#   size using a transformer.\n",
        "image_size = 224\n",
        "\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 3\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "latent_dim = 100\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "g0AW7VZyCmwD",
        "outputId": "629cd799-d984-4437-c54b-2e51775985f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 35332 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "## Load CelebA\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  dataroot,\n",
        "  seed=123,\n",
        "  image_size=(image_size, image_size),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cnB3etAmCmwH"
      },
      "outputs": [],
      "source": [
        "## Preprocessing\n",
        "augmentation_layer = keras.Sequential([\n",
        "    layers.experimental.preprocessing.Rescaling(1./255),\n",
        "    layers.experimental.preprocessing.CenterCrop(image_size,image_size),\n",
        "    layers.experimental.preprocessing.Normalization()    \n",
        "])\n",
        "image_ds = train_ds.map(lambda x,y: (augmentation_layer(x),y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PZHpXWTMCmwJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c090015-713a-41d1-8998-c8bf8e999e2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 112, 112, 64)      3136      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 56, 56, 64)        65600     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 56, 56, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 56, 56, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 64)        65600     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 28, 28, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 14, 14, 128)       131200    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 14, 14, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 7, 7, 256)         524544    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 7, 7, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 4, 4, 512)         2097664   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 4, 4, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 1, 1, 1)           8193      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1)                 0         \n",
            "                                                                 \n",
            " softmax (Softmax)           (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,900,033\n",
            "Trainable params: 2,897,985\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(224, 224, 3)),\n",
        "        layers.Conv2D(64, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(64, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        # First layer. Input: (h,w,c) = (64,64,3)\n",
        "        #keras.Input(shape=(64, 64, 3)),\n",
        "        layers.Conv2D(64, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        # Second layer. Input : (32, 32, 64)     \n",
        "        layers.Conv2D(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        # Third layer. Input : (16, 16, 128)     \n",
        "        layers.Conv2D(256, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),     \n",
        "        # Forth layer. Input : (8, 8, 256)     \n",
        "        layers.Conv2D(512, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        # Last layer, Input : (4, 4, 512)\n",
        "        layers.Conv2D(1, (4, 4), strides=(1, 1)),\n",
        "        layers.Flatten(),\n",
        "        layers.Softmax()\n",
        "\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hwX94j0lCmwN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45caad7c-1c4b-481f-bc44-17a92a1de115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12544)             1254400   \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 12544)            50176     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 12544)             0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 7, 7, 128)        819328    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 7, 7, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 128)      262272    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 14, 14, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 64)       204864    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 28, 28, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_9 (LeakyReLU)   (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 56, 56, 32)       51232     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 56, 56, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_10 (LeakyReLU)  (None, 56, 56, 32)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 112, 112, 16)     12816     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 112, 112, 16)     64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " leaky_re_lu_11 (LeakyReLU)  (None, 112, 112, 16)      0         \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 224, 224, 3)      1203      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,657,763\n",
            "Trainable params: 2,631,939\n",
            "Non-trainable params: 25,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator = keras.Sequential(\n",
        "    [   \n",
        "        \n",
        "        # First layer, Input: (100)\n",
        "        layers.Dense(7*7*256, use_bias=False, input_shape=(100,)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.LeakyReLU(),     \n",
        "        layers.Reshape((7, 7, 256)),\n",
        "        # Second layer, Input: (4, 4, 512)\n",
        "        layers.Conv2DTranspose(128, (5,5), strides=(1, 1), padding=\"same\"),\n",
        "        layers.BatchNormalization(),     \n",
        "        layers.LeakyReLU(),\n",
        "        # Third layer, Input: (8, 8, 256)\n",
        "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "        layers.BatchNormalization(),     \n",
        "        layers.LeakyReLU(),\n",
        "        # Forth layer, Input: (16, 16, 128)\n",
        "        layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding=\"same\"),\n",
        "        layers.BatchNormalization(),     \n",
        "        layers.LeakyReLU(),\n",
        "        layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding=\"same\"),\n",
        "        layers.BatchNormalization(),     \n",
        "        layers.LeakyReLU(),\n",
        "        layers.Conv2DTranspose(16, (5, 5), strides=(2, 2), padding=\"same\"),\n",
        "        layers.BatchNormalization(),     \n",
        "        layers.LeakyReLU(),\n",
        "     \n",
        "        # Final layer, Input: (32, 32, 64)\n",
        "        layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding=\"same\",activation = \"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xGDWG9JOCmwQ"
      },
      "outputs": [],
      "source": [
        "# Instantiate one optimizer for the discriminator and another for the generator.\n",
        "d_optimizer = keras.optimizers.Adam(learning_rate=0.0002)\n",
        "g_optimizer = keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "# Instantiate a loss function.\n",
        "loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "t1wcbbkOCmwS"
      },
      "outputs": [],
      "source": [
        "random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BT8VfprECmwT"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(real_images):\n",
        "    # Sample random points in the latent space\n",
        "    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n",
        "    # Decode them to fake images\n",
        "    generated_images = generator(random_latent_vectors)\n",
        "    # Combine them with real images\n",
        "    combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "    # Assemble labels discriminating real from fake images\n",
        "    labels = tf.concat(\n",
        "        [tf.ones((batch_size, 1)), tf.zeros((real_images.shape[0], 1))], axis=0\n",
        "    )\n",
        "    # Add random noise to the labels - important trick!\n",
        "    labels += 0.05 * tf.random.uniform(labels.shape)\n",
        "\n",
        "    # Train the discriminator\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = discriminator(combined_images)\n",
        "        d_loss = loss_fn(labels, predictions)\n",
        "    grads = tape.gradient(d_loss, discriminator.trainable_weights)\n",
        "    d_optimizer.apply_gradients(zip(grads, discriminator.trainable_weights))\n",
        "\n",
        "    # Sample random points in the latent space\n",
        "    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n",
        "    # Assemble labels that say \"all real images\"\n",
        "    misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "    # Train the generator (note that we should *not* update the weights\n",
        "    # of the discriminator)!\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = discriminator(generator(random_latent_vectors))\n",
        "        g_loss = loss_fn(misleading_labels, predictions)\n",
        "    grads = tape.gradient(g_loss, generator.trainable_weights)\n",
        "    g_optimizer.apply_gradients(zip(grads, generator.trainable_weights))\n",
        "    return d_loss, g_loss, generated_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KdRW4ho2CmxM",
        "outputId": "27c503ee-56fd-4c3f-a0f3-ae2052ce192c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/277 [07:12<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-93ae0c48f42f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Train the discriminator & generator on one batch of real images.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0md_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Logging.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'generator/conv2d_transpose/conv2d_transpose' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1233, in inner\n      self.run()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1147, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n      user_expressions, allow_stdin,\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-13-93ae0c48f42f>\", line 10, in <module>\n      d_loss, g_loss, generated_images = train_step(real_images)\n    File \"<ipython-input-12-7c8709a89fec>\", line 6, in train_step\n      generated_images = generator(random_latent_vectors)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 459, in call\n      inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/layers/convolutional/conv2d_transpose.py\", line 282, in call\n      dilation_rate=self.dilation_rate)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5758, in conv2d_transpose\n      data_format=tf_data_format)\nNode: 'generator/conv2d_transpose/conv2d_transpose'\nDNN library is not found.\n\t [[{{node generator/conv2d_transpose/conv2d_transpose}}]] [Op:__inference_train_step_4648]"
          ]
        }
      ],
      "source": [
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "tf.keras.backend.clear_session()\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"\\nStart epoch\", epoch + 1)\n",
        "\n",
        "    for _, (real_images,_) in enumerate(tqdm(image_ds)):\n",
        "        # Train the discriminator & generator on one batch of real images.\n",
        "        d_loss, g_loss, generated_images = train_step(real_images)\n",
        "\n",
        "    # Logging.\n",
        "    # Print metrics\n",
        "    print(\"discriminator loss at epochs %d: %.2f\" % (epoch + 1, d_loss))\n",
        "    print(\"adversarial loss at epochs %d: %.2f\" % (epoch + 1, g_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 활성화 함수 정리\n",
        "\n",
        "Discriminator 모델에서 흔히 딥러닝 모델에 쓰는 ReLU 대신 Leaky ReLU 함수를 쓰는 것일까요? 그 이유에 대해 알아보기 전, 자주 쓰이는 활성화 함수 네 가지를 정리해 보겠습니다.\n",
        "\n",
        "* 시그모이드\n",
        "\n",
        "output값을 0에서 1 사이로 만들어 주는 비선형 함수입니다.\n",
        "input값이 너무 크거나 작아지면 기울기가 거의 0이 되는 gradient vanishing 현상이 나타날 수 있습니다.\n",
        "\n",
        "* Tanh (하이퍼볼릭탄젠트)\n",
        "\n",
        "시그모이드와 유사하나, -1에서 1 사이의 값을 가집니다. 그렇기 때문에 시그모이드보다 대부분의 경우 학습이 더 잘 이루어집니다.\n",
        "그러나 시그모이드와 마찬가지로 gradient vanishing 현상이 발생할 수 있습니다.\n",
        "\n",
        "그렇다면 gradient vanishing 현상이란 무엇일까요?\n",
        "\n",
        "Gradient Vanishing 현상이란, MLP를 학습시키는 방법인 역전파 (Backpropagation) 중 Gradient항이 사라지는 현상을 말합니다.\n",
        "이 항이 0이 되거나 0에 가까워져서 학습이 불가능해지는 현상인데요!\n",
        "이를 해결하기 위해 딥러닝에서는 ReLu 함수를 가장 많이 사용합니다.\n",
        "\n",
        "* ReLU\n",
        "\n",
        "ReLU 함수는 x값이 양수면 미분값이 1이 되고, x값이 음수면 미분값이 0이 되는 활성화 함수입니다.\n",
        "앞의 두 활성화 함수와 달리 대부분의 input 값에 대해 기울기가 0이 되는 것을 방지하는 함수입니다.\n",
        "그렇기 때문에 학습이 매우 빠른 편입니다. \n",
        "하지만 x가 음수일 때 미분값이 0이 되는 현상, 즉 Dead ReLU 현상이 발생할 수 있는데요!\n",
        "\n",
        "이를 보완한 활성화 함수가 바로 Leaky ReLU 함수입니다.\n",
        "x가 음수일 때 미분값이 0이 되는 것이 아닌 약간의 기울기값을 갖게 하여 Dead ReLU 현상을 보완할 수 있습니다."
      ],
      "metadata": {
        "id": "abGjn7rs6dXZ"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "0dd05da7729844209ebe7ae432159a766a502dd01e52b265c7791d26d8fe0247"
      }
    },
    "colab": {
      "name": "DCGAN_tensorflow_홍은서.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}