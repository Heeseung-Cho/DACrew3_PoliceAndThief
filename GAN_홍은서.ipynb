{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_홍은서.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gUbAFOjY9oxq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GAN\n",
        "\n",
        "Generative Adversarial Nets, Ian Goodfellow et al., NeurIPS, 2014\n",
        "\n",
        "![image](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/2ed4b9e0-76da-432f-9256-aff058cd1988/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220804%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220804T134029Z&X-Amz-Expires=86400&X-Amz-Signature=de1501074980e263367e3131521330283161df2dc6f29f8af5302b8d9f4ae47e&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)\n",
        "\n",
        "#### 개요\n",
        "- Generative model\n",
        "- Generator와 Discriminator가 적대적으로 학습\n",
        "- Generator는 기존 이미지와 유사한 이미지를 생성\n",
        "- Discriminator는 주어진 이미지가 기존 분포(진짜)에 있는지, 혹은 생성된 이미지(가짜)인지 판별\n",
        "- Generator와 Discriminator를 조합한 Loss를 이용하여 학습"
      ],
      "metadata": {
        "id": "FpV4RTVT1QQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gererator가 train data와 유사한 분포를 가지는 이미지를 생성해 내면 Discriminator는 생성된 이미지가 진짜인지 가짜인지 판별하는 역할을 합니다.\n",
        "\n",
        "Generator와 Discriminator는 따로 학습을 하게 되지만 로스 개념(수식)이 G와 D 모두에게 영향을 줍니다."
      ],
      "metadata": {
        "id": "5ZRNQxy7cqaK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 상세\n",
        "\n",
        "- Generator와 Discriminator의 minimax 게임\n",
        "- $min_G max_D V(D,G) = E_{x\\sim p_{data}(x)}[log D(x)] + E_{x\\sim p_z(x)}[log(1- D(G(z)))]$\n",
        "- $D(x) = \\frac{p_{data}(x)}{p_{data}(x) + p_z(x)}$\n",
        "- Generator는 가짜 데이터를 진짜 데이터처럼 학습시키려 함\n",
        "- Discriminator는 진짜 데이터를 더 잘 파악하려 함\n",
        "- 결과적으로 $D(x)$는 1/2로 수렴하게 됨\n",
        "\n",
        "![image](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/59543418-0b8f-44b7-a4ca-675336e2036f/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220801%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220801T104906Z&X-Amz-Expires=86400&X-Amz-Signature=2e91ddf61ddf5f569540ebf309378cbf73d313aa1ae198a1da1788d5310e798d&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject)"
      ],
      "metadata": {
        "id": "6Cxn9RQK1iny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- GAN framework\n",
        "\n",
        "Discriminator가 x의 진위 여부를 정확하게 판단하도록 학습시킴($D(x)$를 1로 수렴)과 동시에 Generator가 Discriminator를 잘 속일 수 있도록 학습시켜야($log(1- D(G(z)))$ 최소화) 합니다. "
      ],
      "metadata": {
        "id": "4W6gkty7UkP6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "수식이 매우 어렵게 느껴지실 분들을 위해 더 자세하게 설명해 드리겠습니다!\n",
        "\n",
        "1. $D(x)$를 1로 만드는 경우 (판별자가 모든 것을 분류할 수 있는 경우)\n",
        "\n",
        "$D(x)=1$인 상황은 $logD(x)$가 0이 되는 상황과 같습니다. $D(x)=1$이라는 의미는 판별자가 모든 것의 진위 여부를 정확하게 판별할 수 있음을 의미합니다. 이렇게 되면 동시에 $D(G(z))$가 1이 됩니다. Generator가 아무리 진짜와 같은 이미지를 생성하더라도 Discriminator가 100%의 확률로 전부 잡아낼 수 있기 때문이죠! 결과적으로 수식의 $logD(x)$는 0이 되어 사라지고, 뒷 부분은 $log(1-1)$이 되어 무한에 수렴하게 됩니다.\n",
        "\n",
        "\n",
        "2. $G(z)$를 1로 만드는 경우 (판별자가 모든 것을 분류하지 못하는 경우) \n",
        "\n",
        "$G(z)=1$인 상황은 Generator가 실제와 구분하지 못할 정도로 이미지를 비슷하게 만들어 Discriminator가 하나도 구분하지 못하는 상황과 같습니다. 이렇게 되면 수식의 앞 부분인 $logD(x)$는 $log0$이 되어 무한에 수렴하게 되고, 뒷 부분인 $log(1-D(G(z))$는 0이 되어 사라지게 됩니다."
      ],
      "metadata": {
        "id": "nPUtx3YsgF59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GAN은 Generator와 Discriminator의 minimax 게임이라고 할 수 있습니다.\n",
        "\n",
        "\n",
        "Generator와 Discriminator 중 하나의 모델이 더 강해지게 되면 학습력이 떨어집니다. \n",
        "\n",
        "결과적으로 D(x)를 0.5로 수렴시키는 것이 목표기 때문에 두 모델 간의 밸런스를 잘 맞추는 것이 매우 중요하겠습니다!  ;)"
      ],
      "metadata": {
        "id": "g0Mt1UaQh-Qq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- GAN 장점 보충\n",
        "\n",
        "GAN은 CatGANs의 도입 이후로 준지도 학습에 성공적으로 적용되었습니다. \n",
        "\n",
        "일반적으로 지도학습 모델은 50,000개 이상의 레이블을 사용하여 데이터셋에 대해 훈련되지만 feature matching GANs은 매우 적은 레이블로 우수한 성능을 얻을 수 있습니다.\n",
        "\n",
        "다른 복잡한 네트워크 필요 없이 오직 forward/back propagation이나 dropout algorithm으로 학습이 가능합니다."
      ],
      "metadata": {
        "id": "3RG_6onkbLrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 마르코프 체인(Markov chain)이란?\n",
        "\n",
        "마르코프 체인의 정의란 마르코프 성질을 가진 이산 확률과정을 뜻한다. 마르코프 성질은 ‘특정 상태의 확률은 오직 과거의 상태에 의존한다’라는 것이다. 대표적인 문제로는 어제와 오늘의 날씨로 내일의 날씨에 대해 확률적으로 표현하는 것이 그 예이다. 이러한 연속적인 현상을 단순히 표현할 때는 마르코프 체인을 가정하고 쓸 수 있고, 종종 단순한 모델이 강력한 효과를 발휘할 때도 있다.\n",
        "\n",
        "\n",
        "\n",
        "- 근사 추론(approximate inference)이란?\n",
        "\n",
        "여기서 말하는 inference는 어떤 현상을 설명하기 위한 Model이 완성된 이후 이 Model을 근거로 다른 질문을 던진다는 뜻이다. Inference는 우리가 만든 Model로부터 직접적인 답(확률값)을 도출하는 경우에 사용된다."
      ],
      "metadata": {
        "id": "Og6JVOkzk_53"
      }
    }
  ]
}