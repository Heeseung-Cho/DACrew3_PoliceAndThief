{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1장. 생성모델이란 무엇인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "안녕하세요. 데이크루 3기 👮**경도(경찰과 도둑)**팀 입니다!\n",
    "\n",
    "저희는 **“딥러닝을 활용한 이미지 생성모델”**이란 주제로 8주동안 함께 공부하고, 공부한 내용을 게시글로써 데이콘 이용자분들께 공유하고자 합니다.\n",
    "\n",
    "첫 번째 포스팅의 주제는 **생성모델이란 무엇인가?** 입니다.\n",
    "\n",
    "저희가 같이 공부할 생성모델이 어떤 내용인지 같이 알아보도록 하겠습니다!\n",
    "\n",
    "**본 포스팅은 데이콘 서포터즈 “데이크루” 3기 활동의 일환입니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "De8t4uTiyIv4"
   },
   "source": [
    "## 1. 생성 모델이란?\n",
    "\n",
    " 말 그대로 데이터를 생성해내는 모델입니다.\n",
    " \n",
    " 그러나 기존에 없던 데이터를 아무렇게나 만들 수는 없겠죠? 그래서 생성모델은 주어진 데이터를 바탕으로, **해당 데이터의 분포를 따르는 유사하지만 기존에는 없던 새로운 데이터를 생성해내는 모델**을 말합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36kzFN1myW0k"
   },
   "source": [
    "## 2. 생성 모델의 관심사\n",
    "\n",
    "생성모델은 모델을 통해 데이터의 분포를 학습하는 것을 목표로 하고 있습니다.\n",
    "\n",
    "구체적으로는 데이터가 가지고 있는 **latent space**를 학습한다고 합니다. 그렇다면 이 latent space라는 것은 무엇일까요?\n",
    "\n",
    "**Latent란 데이터가 가지고 있는 잠재적인 변수입니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T11:04:49.945575Z",
     "start_time": "2022-07-12T11:04:49.926610Z"
    }
   },
   "source": [
    "<img src=\"latent.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "in2V9JqwybET"
   },
   "source": [
    "**Latent vector**는 한 이미지가 가지고 있는 잠재적인 벡터 형태의 변수입니다. 그리고 이런 latent vector들이 모여서 **latent space**가 형성이 됩니다. \n",
    "\n",
    "Latent space에는 우리가 학습시킬 이미지들이 latent vector의 **분포** 형태로 존재하게 되고 우리는 모델을 통해서 이미지가 가지고 있는 latent의 분포를 학습하게 됩니다.\n",
    "\n",
    " 이는 기존의 classification 및 detection 하는 과정과는 조금 다른데요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"feature.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnkAba5jy0Ft"
   },
   "source": [
    "그림과 같이 classification과 detection에서는 이미지에서 CNN과 같은 모델을 통해 이미지가 가지고 있는 feature들을 벡터화 합니다. 이미지와 벡터라는 관계에서는 feature와 유사하다고 볼 수 있습니다. \n",
    "\n",
    " 그러나 해당 task에서는 학습과정에서 하나의 이미지에 대해 이를 표현하는 feature가 달라지지만, 생성모델에서는 하나의 latent에 대해 이를 표현하는 image가 달라집니다. **이미지에서 벡터**로 가는 과정이 기존의 classification과 detection에서 하는 작업이라면, 생성모델은 반대로 **벡터에서 이미지로** 가는 학습과정을 거치게 됩니다.\n",
    " \n",
    " 이러한 관점을 한번에 보여주는 모델이 Autoencoder라고 볼 수 있습니다. Encoder 부분에서는 우리가 이미지에서 feature 벡터로 가는 과정을, Decoder에서는 이 feature가 latent 형태에서 다시 이미지로 재구축 되는 과정을 한번에 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"AE.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "생성모델은 latent space를 학습해야 하므로, 분포에 대해서 관심이 많습니다. 따라서 Loss나 evaluation metrics 또한 기존 task들과는 다른 지표를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📖 **Loss**\n",
    "\n",
    "* Classification의 **Cross Entropy** : 라벨을 어느정도의 확률로 잘 맞추는가?\n",
    "\n",
    "* Detection의 **Focal loss** : 물체를 얼마나 잘 포착하는가? \n",
    "\n",
    "* GAN의 **KL-Divergence** : 데이터 분포가 얼마나 비슷한가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📖 **Evaluation metrics** \n",
    "* Classification의 **ACC, AUC, F1 score** : 라벨을 얼마나 정확히 맞추는가?\n",
    "\n",
    "* Detection의 **mAP**, Segmentation의 **IoU** : 어느정도로 영역이 잘 겹치는가?\n",
    "\n",
    "* GAN의 **FID(Frechet Inception Distance)** : 분포가 얼마나 비슷한가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 생성 모델의 역사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 시간에는 간단하게 생성모델에 대한 역사를 훑어보겠습니다! 구체적인 모델의 구조 및 동작 방법은 이후에 같이 알아가 볼 예정입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"gan_history.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) GAN(Generative Adverserial Network, 2014)\n",
    "\n",
    " 생성모델로써 가장 잘 알려진 **GAN**은 저희 경도팀이 목표로 하는 대표적인 모델입니다. 이미지를 생성하는 **Generator**와 이를 구별하는 **Discriminator**가 서로 **적대적으로 학습**하는 과정을 거쳐 Generator는 더욱 질이 좋은 이미지를 생산해내도록, Discriminator는 해당 이미지가 진짜인지 가짜인지 더 잘 구별하도록 학습을 하게 됩니다.\n",
    "\n",
    " 이를 비유할 때 마치 Generator를 가짜 지폐를 생산하려는 **도둑**, Discriminator는 주어진 지폐가 진짜인지 가짜인지 판단하는 **경찰**로 많이 설명하곤 합니다. 저희 팀의 이름이 경도 팀이 된 이유죠! 😉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T11:08:23.204915Z",
     "start_time": "2022-07-12T11:08:23.190880Z"
    }
   },
   "source": [
    "<img src=\"policeandthief.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) DCGAN(Deep Convolutional GAN, 2015)\n",
    "\n",
    "**DCGAN**은 GAN에서 파생된 모델입니다. **MLP**(완전연결신경망) 형태의 GAN에 **Convolution**(합성곱)을 적용한 형태를 말합니다. 현재의 DCGAN을 기반으로 GAN의 모델들이 만들어지고 있습니다. 또한, latent끼리의 연산을 결과물에 적용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-12T11:08:51.224808Z",
     "start_time": "2022-07-12T11:08:51.212808Z"
    }
   },
   "source": [
    "<img src=\"dcgan.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) CycleGAN(2017), StarGAN(2018)\n",
    "\n",
    "GAN에 **style transfer**를 적용한 모델로 아래 이미지에서 처럼 머리색이나, 표정, 성별, 나이 등 원본 input에 다양한 스타일 값을 이용해 변환을 하는 방법으로도 이용이 가능합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cyclegan.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) PGGAN(2018), StyleGAN(2019)\n",
    "\n",
    "모니터도 4k 모니터를 사는 시대…  시대의 트랜드를 반영하듯 화질은 포기못하는 사람들을 위한 기존의 이미지들보다 뛰어난 **해상도**의 이미지를 생성하는 모델들, 거기에 앞서 보았던 style transfer를 더해 이전까지의 GAN 모델들보다 고해상도의 다양한 스타일의 이미지를 생성할 수 있게 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"stylegan.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) 현재 트랜드\n",
    "\n",
    "생성모델은 발전을 거듭해 최근에는 **Diffusion**이라는 모델을 이용하여 StyleGAN보다 더욱 더 고화질의 리얼한 이미지를 생성하고 있습니다. 대표적으로 **DALL-E, Imagen, Parti**가 있습니다.\n",
    "\n",
    "텍스트를 입력하면 존재하지 않는 사진을 AI가 직접 만들어 준다니, 너무 신기하지 않나요? ㄴ(°0°)ㄱ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dalle2.png\" width=\"600\" height=\"600\">\n",
    "<img src=\"imagen.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 생성 모델의 활용\n",
    "\n",
    "앞서 말씀드렸듯이, 생성모델의 관심사는 모델을 통해 데이터의 분포를 학습하는 데 있습니다. \n",
    "\n",
    "아무리 AI가 학습할 수 있는 데이터가 무궁무진하더라도, 결국에는 한계가 있을 수 밖에 없습니다. 컴퓨터 비전에서 가장 많은 데이터셋이라고 알려진 JFT300 데이터셋도 **3억** 개라는 어마어마한 숫자의 이미지를 포함하고 있지만 유한한 데이터에 불과하죠? 하지만 가지고 있는 데이터들을 통해 우리가 원하는 **데이터의 분포**를 알게 된다면 분포를 통해서 여러 방법의 데이터 조작이 가능해집니다.\n",
    "\n",
    "유한한 데이터에서 분포를 통해 우리가 원하는 데이터를 확보할 수 있게 되는 것이죠!\n",
    "\n",
    "따라서 생성모델은 다음과 같이 활용될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Image generation\n",
    "생성모델은 기본적으로 주어진 이미지를 학습하여 새로운 이미지를 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ex1.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Style transfer\n",
    "\n",
    "또한, 생성 과정에서 약간의 style을 제공함으로써 **생성하려는 이미지의 스타일을 변화**시킬 수 있습니다.  이를 통해 같은 사람에서 나이를 변화시킨다거나, 머리 색깔, 표정 등의 변화를 줄 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ex2.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Image reconstruction\n",
    "\n",
    "또한, 생성 모델을 통하여 **이미지를 복원**할 수 있습니다. 다음과 같이 주어진 이미지가 잘려져 있을 때 이를 채워넣기 위해 주변의 이미지와 가장 유사한 latent를 이용해 채워줄 수 있습니다. 국내에서는 이를 활용하여 2022년에 AIChallenge에서 이미지 복원에 대한 경진대회를 주최한 적이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ex3.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 마치며\n",
    "이번 포스팅에서는 생성모델이란 무엇이며, 어떻게 학습을 하는가에 대한 대략적인 개요를 알아보았습니다! 흥미가 조금 생기셨나요? 😎\n",
    "\n",
    "GAN은 교통, 금융, 의료 등 정말 다양한 분야에서 활용도가 높은 모델이기 때문에 공부해 두면 아주 도움이 될 거라는 점 XD\n",
    "\n",
    "다음 포스팅에서는 생성모델 구현을 위한 첫 단계로서 **tensor**에 대해 다루어 보도록 하겠습니다.\n",
    "\n",
    "저희 크루원들을 **팔로우** 해 주시면 더욱 빠르게 새로운 정보를 열람하실 수 있습니다. \n",
    "\n",
    "읽어 주셔서 감사합니다. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- **Tutorial: Generative Adversarial Networks, Ian Goodfellow, NeurIPS, 2016**\n",
    "- **Semantic Image Inpainting with Deep Generative Models, RA. Yeh et al., CVPR, 2017**\n",
    "- **DALL-E, DALL-E2**, [https://openai.com/blog/dall-e/](https://openai.com/blog/dall-e/), [https://openai.com/dall-e-2/](https://openai.com/dall-e-2/)\n",
    "- **Imagen**, [https://imagen.research.google/](https://imagen.research.google/)\n",
    "- **Parti**, [https://parti.research.google/](https://parti.research.google/)\n",
    "- **한땀한땀 딥러닝 컴퓨터 비전 백과사전, [https://wikidocs.net/152474](https://wikidocs.net/152474)**\n",
    "- [Toonify!](https://toonify.photos/)\n",
    "- [딥러닝 ‘생성모델’과 ‘잠재 벡터’에 관하여 – AI PLUS Tech Blog (est.ai)](https://blog.est.ai/2021/09/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%83%9D%EC%84%B1%EB%AA%A8%EB%8D%B8%EA%B3%BC-%EC%9E%A0%EC%9E%AC-%EB%B2%A1%ED%84%B0%EC%97%90-%EA%B4%80%ED%95%98%EC%97%AC/)\n",
    "- [[떠오르는 인공지능 기술, GAN ]제2부_GAN의 개념과 응용사례 (ahnlab.com)](https://blogsabo.ahnlab.com/2606)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "이론 코드 공유 파일 예시.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
